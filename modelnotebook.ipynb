{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from src.footballproject.exception import CustomException\n",
    "from src.footballproject.logger import logging\n",
    "from src.footballproject.utils import save_object\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/rawdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your original DataFrame\n",
    "\n",
    "# Bootstrapping to increase dataset size\n",
    "def bootstrap_data(data, num_samples):\n",
    "    bootstrapped_data = pd.concat([data.sample(frac=1, replace=True) for _ in range(num_samples)], ignore_index=True)\n",
    "    return bootstrapped_data\n",
    "\n",
    "# Increase the training size by bootstrapping\n",
    "bootstrapped_df = bootstrap_data(df, num_samples=4)  # Example: Increase the size by 10 times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = bootstrapped_df\n",
    "df.to_csv('model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Home', 'xG_Home', 'xG_Away', 'Away', 'Referee', 'xGA_Home',\n",
       "       'xGA_Away', 'Home_Fatigue', 'Away_Fatigue', 'Temp', 'Humidity', 'Wind',\n",
       "       'Referee_Bias', 'G_Home', 'G_Away', 'Result'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['xG_Diff'] = df['xG_Home'] - df['xG_Away']\n",
    "df['xGA_Diff'] = df['xGA_Home'] - df['xGA_Away']\n",
    "\n",
    "df['xGA_Ratio_Home'] = df['xGA_Home'] / (df['xG_Home'] + 0.1)\n",
    "df['xGA_Ratio_Away'] = df['xGA_Away'] / (df['xG_Away'] + 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['G_Home', 'G_Away','Date','Referee'], axis=1, inplace=True)\n",
    "df.drop(['Home','Away'], axis=1,inplace=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_name=\"Result\"\n",
    "X = df.drop(columns = target_column_name, axis = 1)\n",
    "y = df[target_column_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    'xG_Home','xG_Away','xGA_Home','xGA_Away','xG_Diff','xGA_Diff','xGA_Ratio_Home','xGA_Ratio_Away'\n",
    "]\n",
    "\n",
    "ordinal_columns = [\n",
    "    \"Temp\", \"Humidity\", \"Wind\", \"Home_Fatigue\", \"Away_Fatigue\",\"Referee_Bias\"\n",
    "]\n",
    "\n",
    "# categorical_columns = [\"Result\"]\n",
    "\n",
    "categories_1 = [['Low', 'Moderate', 'High']] * 5\n",
    "categories_2 = ['Home','Away']\n",
    "categories_1.append(categories_2)\n",
    "\n",
    "\n",
    "num_pipeline=Pipeline(steps=[\n",
    "    ('scalar',StandardScaler())\n",
    "\n",
    "])\n",
    "\n",
    "# cat_pipeline=Pipeline(steps=[\n",
    "#     (\"one_hot_encoder\",LabelEncoder()),\n",
    "#     (\"scaler\",StandardScaler())\n",
    "# ])\n",
    "\n",
    "ord_pipeline=Pipeline(steps=[\n",
    "    ('ordinal', OrdinalEncoder(categories=categories_1)),\n",
    "    (\"scaler\",StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numerical_pipeline', num_pipeline,numerical_columns ),\n",
    "    # ('categorical_pipeline', cat_pipeline,categorical_columns ),\n",
    "    ('ordinal_pipeline', ord_pipeline,ordinal_columns )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Home': 3310, 'Away': 2427, 'Draw': 1711})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate and plot a synthetic imbalanced classification dataset\n",
    "from collections import Counter\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(k_neighbors=5, random_state=42)\n",
    "X, y = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Home': 3310, 'Away': 3310, 'Draw': 3310})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate and plot a synthetic imbalanced classification dataset\n",
    "from collections import Counter\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "            \"Random Forest\": RandomForestClassifier(n_estimators=120, max_depth=9, random_state=42,min_samples_split=3),\n",
    "            \"Logistic Regression\": LogisticRegression(random_state=42,C = 1, max_iter= 10000, penalty= 'l1', solver = 'saga'),\n",
    "            \"KNN\": KNeighborsClassifier(n_neighbors=4),\n",
    "            \"Linear SVC\": LinearSVC(C=10, random_state=42,dual=False, max_iter=1000, tol=1e-9,class_weight='balanced',penalty='l1'),\n",
    "            \"Naive Bayes\": GaussianNB(var_smoothing=1e-11)\n",
    "\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=150, max_depth=10, random_state=42,min_samples_split=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.8872104733131924, 0.8992950654582075, 0.8801611278952669, 0.892245720040282, 0.8937562940584088]\n",
      "Mean CV Score: 0.8905337361530716\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "for train_index, val_index in kf.split(X,y):\n",
    "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "    \n",
    "    # Train the model on the training fold\n",
    "    rf_model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Evaluate the model on the validation fold\n",
    "    score = rf_model.score(X_val_fold, y_val_fold)\n",
    "    scores.append(score)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "\n",
    "print(\"Mean CV Score:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8905337361530716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Away       0.92      0.89      0.90      3310\n",
      "        Draw       0.86      0.92      0.89      3310\n",
      "        Home       0.90      0.86      0.88      3310\n",
      "\n",
      "    accuracy                           0.89      9930\n",
      "   macro avg       0.89      0.89      0.89      9930\n",
      "weighted avg       0.89      0.89      0.89      9930\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# Split data using stratified KFold\n",
    "skf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "accuracy_scores = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train the model on the current fold\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and calculate accuracy on the test set\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "    # print(confusion_matrix(y_test, y_pred))\n",
    "    true_labels.extend(y_test)\n",
    "    predicted_labels.extend(y_pred)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "    # print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Calculate and print the average accuracy and standard deviation\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "\n",
    "print(\"Average accuracy:\", average_accuracy)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Generate the final classification report\n",
    "classification_rep = classification_report(true_labels, predicted_labels)\n",
    "\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_grid = {\n",
    "    'n_estimators': [50, 100, 150],  # Number of trees in the forest\n",
    "    'max_depth': [3,4,5,6,7,8,9,10],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2,3,4,5,6,7,8,9,10],  # Minimum number of samples required to split an internal node\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best random forest parameters: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Best Score: 0.8827278459293838\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "cv = 5\n",
    "\n",
    "randomforest_clf = GridSearchCV(rf_model, randomforest_grid, cv=cv, scoring='f1_macro')\n",
    "randomforest_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best random forest parameters:\", randomforest_clf.best_params_)\n",
    "print(\"Best Score:\", randomforest_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8465256797583083\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Away       0.86      0.88      0.87      3310\n",
      "        Draw       0.81      0.91      0.86      3310\n",
      "        Home       0.89      0.75      0.81      3310\n",
      "\n",
      "    accuracy                           0.85      9930\n",
      "   macro avg       0.85      0.85      0.85      9930\n",
      "weighted avg       0.85      0.85      0.85      9930\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# Split data using stratified KFold\n",
    "skf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "accuracy_scores = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    knn_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    true_labels.extend(y_test)\n",
    "    predicted_labels.extend(y_pred)\n",
    "\n",
    "\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "\n",
    "print(\"Average accuracy:\", average_accuracy)\n",
    "\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "classification_rep = classification_report(true_labels, predicted_labels)\n",
    "\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
